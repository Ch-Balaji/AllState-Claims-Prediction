{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_pipeline(raw_input):\n",
    "    train_data = pd.read_csv('../input/train-dataset/train.csv')\n",
    "    test_data  = pd.read_csv('../input/test-orig/test.csv',nrows=1)\n",
    "    test_data.loc[len(test_data)] = raw_input\n",
    "    \n",
    "    test_data['loss'] = np.nan\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "    categorical_features = list(train_data.select_dtypes(include = ['object']).columns)\n",
    "\n",
    "    no_common = []\n",
    "    for i in categorical_features:\n",
    "        if train_data[i].nunique() != test_data[i].nunique():\n",
    "            no_common.append(i)\n",
    "\n",
    "    def log_xgboost_eval_mae(pred,dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        a = mean_absolute_error(np.exp(pred),np.exp(labels))\n",
    "        return 'mae',a\n",
    "\n",
    "    def search_feature(x):\n",
    "        if x in combined_remaining:\n",
    "            return np.nan\n",
    "        return \n",
    "\n",
    "    for i in categorical_features:\n",
    "        if train_data[i].nunique() != test_data[i].nunique():\n",
    "            train_unique_set = set(train_data[i].unique())\n",
    "            test_unique_set  = set(test_data[i].unique())\n",
    "            remaining_train  = train_unique_set - test_unique_set\n",
    "            remaining_test   = test_unique_set - train_unique_set\n",
    "\n",
    "            combined_remaining = remaining_train.union(remaining_test)\n",
    "\n",
    "            combined_data[i] = combined_data[i].apply(lambda x: search_feature(x),1)\n",
    "        combined_data[i] = pd.factorize(combined_data[i].values,sort = True)[0]\n",
    "\n",
    "    x_train = combined_data[combined_data['loss'].notnull()]\n",
    "    x_test = combined_data[combined_data['loss'].isnull()]\n",
    "\n",
    "    shift = 200\n",
    "    y_train = np.log(x_train['loss']+shift)\n",
    "    x_train = x_train.drop(['loss','id'],axis = 1)\n",
    "    x_test  = x_test.drop(['loss','id'],axis = 1)\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    xgtest = xgb.DMatrix(x_test)\n",
    "    \n",
    "    file_name = \"/kaggle/input/best-model/xgb_reg_model.pkl\"\n",
    "    xgb_model_loaded = pickle.load(open(file_name, \"rb\"))\n",
    "    prediction = np.exp(xgb_model_loaded.predict(xgtest)) - shift\n",
    "\n",
    "    \n",
    "    print('Predicted loss for the given raw_input is :-',prediction[-1])\n",
    "    \n",
    "    prediction = prediction[-1]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted loss for the given raw_input is :- 1996.604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1996.604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input = [17, 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'D', 'B', 'B', 'D', 'D', 'B', 'A', 'C', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'D', 'E', 'A', 'A', 'P', 'H', 'A', 'A', 'C', 'H', 'G', 'G', 'D', 'B', 'BI', 'CL', 'A', 'AN', 'BC', 'A', 'I', 'HY', 0.594934, 0.245921, 0.397983, 0.849584, 0.643315, 0.407351, 0.39054, 0.46476999999999996, 0.46853, 0.50556, 0.6075, 0.594646, 0.25099099999999996, 0.283976]\n",
    "Final_pipeline(raw_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_pipeline2(raw_input,loss):\n",
    "    train_data = pd.read_csv('../input/train-dataset/train.csv')\n",
    "    test_data  = pd.read_csv('../input/test-orig/test.csv',nrows=1)\n",
    "    test_data.loc[len(test_data)] = raw_input\n",
    "    \n",
    "    test_data['loss'] = np.nan\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "    categorical_features = list(train_data.select_dtypes(include = ['object']).columns)\n",
    "\n",
    "    no_common = []\n",
    "    for i in categorical_features:\n",
    "        if train_data[i].nunique() != test_data[i].nunique():\n",
    "            no_common.append(i)\n",
    "\n",
    "    def log_xgboost_eval_mae(pred,dtrain):\n",
    "        labels = dtrain.get_label()\n",
    "        a = mean_absolute_error(np.exp(pred),np.exp(labels))\n",
    "        return 'mae',a\n",
    "\n",
    "    def search_feature(x):\n",
    "        if x in combined_remaining:\n",
    "            return np.nan\n",
    "        return \n",
    "\n",
    "    for i in categorical_features:\n",
    "        if train_data[i].nunique() != test_data[i].nunique():\n",
    "            train_unique_set = set(train_data[i].unique())\n",
    "            test_unique_set  = set(test_data[i].unique())\n",
    "            remaining_train  = train_unique_set - test_unique_set\n",
    "            remaining_test   = test_unique_set - train_unique_set\n",
    "\n",
    "            combined_remaining = remaining_train.union(remaining_test)\n",
    "\n",
    "            combined_data[i] = combined_data[i].apply(lambda x: search_feature(x),1)\n",
    "        combined_data[i] = pd.factorize(combined_data[i].values,sort = True)[0]\n",
    "\n",
    "    x_train = combined_data[combined_data['loss'].notnull()]\n",
    "    x_test = combined_data[combined_data['loss'].isnull()]\n",
    "\n",
    "    shift = 200\n",
    "    y_train = np.log(x_train['loss']+shift)\n",
    "    x_train = x_train.drop(['loss','id'],axis = 1)\n",
    "    x_test  = x_test.drop(['loss','id'],axis = 1)\n",
    "    \n",
    "    xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "    xgtest = xgb.DMatrix(x_test)\n",
    "    \n",
    "    file_name = \"/kaggle/input/best-model/xgb_reg_model.pkl\"\n",
    "    xgb_model_loaded = pickle.load(open(file_name, \"rb\"))\n",
    "    prediction = np.exp(xgb_model_loaded.predict(xgtest)) - shift\n",
    "\n",
    "    print('Actual Value is :-',loss)\n",
    "    print('Predicted loss for the given raw_input is :-',prediction[-1])\n",
    "    print('Diff in estimated vlaue and given value is :-',np.abs(loss-prediction[-1]))\n",
    "    \n",
    "    \n",
    "    prediction = prediction[-1]\n",
    "    \n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value is :- 1283.6\n",
      "Predicted loss for the given raw_input is :- 1597.0173\n",
      "Diff in estimated vlaue and given value is :- 313.4173339843751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1597.0173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input= [2, 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'D', 'B', 'B', 'D', 'D', 'A', 'B', 'C', 'B', 'D', 'B', 'A', 'A', 'A', 'A', 'A', 'D', 'D', 'C', 'E', 'E', 'D', 'T', 'L', 'F', 'A', 'A', 'E', 'E', 'I', 'K', 'K', 'BI', 'CQ', 'A', 'AV', 'BM', 'A', 'O', 'DP', 0.330514, 0.7370680000000001, 0.592681, 0.6141340000000001, 0.885834, 0.438917, 0.43658500000000006, 0.60087, 0.35126999999999997, 0.43918999999999997, 0.338312, 0.366307, 0.6114310000000001, 0.304496]\n",
    "Final_pipeline2(raw_input, 1283.6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
