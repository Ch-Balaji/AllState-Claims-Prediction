{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/train-dataset/train.csv\n",
      "/kaggle/input/train-dataset/test.csv\n",
      "/kaggle/input/submission/sample_submission.csv\n",
      "/kaggle/input/model-save/Model_Save.txt\n",
      "/kaggle/input/test-orig/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing All Modeules that we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "* We loaded the data into train_data and test_data\n",
    "* seperated feature names , categorical feature names and continous feature names.\n",
    "* Done label encoding.\n",
    "* Added a feature which is a log transformation with some shift on loss feature. Why this should be done is explained in the EDA part of the code.\n",
    "* seperated x_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind data from csv files.....\n",
      "shape of train data : (188318, 132)\n",
      "shape of test data : (125546, 131)\n",
      "Joining complete....\n",
      "shape of combined data: (313864, 132)\n",
      "Total number of categorical features in data are : 116\n",
      "Features that have diff unique values in train and test are :\n",
      "['cat90', 'cat92', 'cat96', 'cat99', 'cat101', 'cat102', 'cat103', 'cat105', 'cat106', 'cat109', 'cat110', 'cat113', 'cat114', 'cat116']\n"
     ]
    }
   ],
   "source": [
    "print('Loadind data from csv files.....')\n",
    "train_data = pd.read_csv('../input/train-dataset/train.csv')\n",
    "test_data  = pd.read_csv('../input/test-orig/test.csv')\n",
    "print('shape of train data :',train_data.shape)\n",
    "print('shape of test data :',test_data.shape)\n",
    "\n",
    "\n",
    "test_data['loss'] = np.nan\n",
    "combined_data = pd.concat([train_data, test_data])\n",
    "print('Joining complete....')\n",
    "print('shape of combined data:',combined_data.shape)\n",
    "\n",
    "\n",
    "categorical_features = list(train_data.select_dtypes(include = ['object']).columns)\n",
    "print('Total number of categorical features in data are :', len(categorical_features))\n",
    "\n",
    "no_common = []\n",
    "for i in categorical_features:\n",
    "    if train_data[i].nunique() != test_data[i].nunique():\n",
    "        no_common.append(i)\n",
    "print('Features that have diff unique values in train and test are :')\n",
    "print(no_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_xgboost_eval_mae(pred,dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    a = mean_absolute_error(np.exp(pred),np.exp(labels))\n",
    "    return 'mae',a\n",
    "\n",
    "def search_feature(x):\n",
    "    if x in combined_remaining:\n",
    "        return np.nan\n",
    "    return \n",
    "\n",
    "#Reference https://www.geeksforgeeks.org/python-pandas-factorize/\n",
    "#Reference https://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe\n",
    "\n",
    "for i in categorical_features:\n",
    "    if train_data[i].nunique() != test_data[i].nunique():\n",
    "        train_unique_set = set(train_data[i].unique())\n",
    "        test_unique_set  = set(test_data[i].unique())\n",
    "        remaining_train  = train_unique_set - test_unique_set\n",
    "        remaining_test   = test_unique_set - train_unique_set\n",
    "        \n",
    "        combined_remaining = remaining_train.union(remaining_test)\n",
    "        \n",
    "        combined_data[i] = combined_data[i].apply(lambda x: search_feature(x),1)\n",
    "    combined_data[i] = pd.factorize(combined_data[i].values,sort = True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How i handled categrocal features having diff unique values in train and test data\n",
    "* I created an array which consists of unique values for a particual feature that are either in train or test data but not in both.\n",
    "* function search_feature returns a variable if it should not be removed and returns nan if it should be removed.\n",
    "* After applying search feature for a column, it returns ctegorical variables and NAN values\n",
    "* after that i used pandas factorize feature which returns and replaces all categorical variables by integers and NAN by -1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making data model ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130)\n",
      "(125546, 130)\n"
     ]
    }
   ],
   "source": [
    "x_train = combined_data[combined_data['loss'].notnull()]\n",
    "x_test = combined_data[combined_data['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y_train = np.log(x_train['loss']+shift)\n",
    "x_train = x_train.drop(['loss','id'],axis = 1)\n",
    "x_test  = x_test.drop(['loss','id'],axis = 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to run multiple regression models\n",
    "* Why is the need to this?\n",
    "\n",
    "* As this is a regression analysis,i wanted to apply multiple types of regression techniques that are mentioned below.\n",
    "* Apply regression models without any hyperparamter tuning.\n",
    "* once the models are completed , will check a score on cv dataset on which will give less error.\n",
    "* Than will choose that as a primary regression model for out final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(x_train,y_train,x_cv,y_cv):\n",
    "    model_xgb = XGBRegressor()\n",
    "    model_adb = AdaBoostRegressor()\n",
    "    model_rf  = RandomForestRegressor()\n",
    "    model_gbd = GradientBoostingRegressor()\n",
    "    model_knn = KNeighborsRegressor()\n",
    "    model_eln = ElasticNet()\n",
    "    model_las = Lasso()\n",
    "    model_rid = Ridge()\n",
    "    model_lr  = LinearRegression()\n",
    "    model_dt  = DecisionTreeRegressor()\n",
    "    \n",
    "    models = [model_xgb,model_adb,model_rf,model_gbd,model_knn,model_eln,model_las,model_rid,model_lr,model_dt]\n",
    "    model_dict = {}\n",
    "    \n",
    "    for i in models:\n",
    "        model = i\n",
    "        model.fit(x_train,y_train)\n",
    "        pred =  model.predict(x_cv)\n",
    "        a = mean_absolute_error(np.exp(y_cv), np.exp(pred))\n",
    "        model_dict.update({i:a})\n",
    "        \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train data into train and cv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1,x_cv1,y_train1,y_cv1 = train_test_split(x_train,y_train,test_size = 0.2)\n",
    "model_dict = run_models(x_train1,y_train1,x_cv1,y_cv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting histogram distribution of MAE values over all trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAE_vales = model_dict.values()\n",
    "models = ['model_xgb','model_adb','model_rf','model_gbd','model_knn','model_eln','model_las','model_rid','model_lr','model_dt']\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAE scores')\n",
    "plt.bar(models,MAE_vales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0oAAAHxCAYAAABTSExyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfbh1ZV0v+u9PUUQQUnlE4919UAMyC+RQuotSLy13QaYH2BpknkO6uXJXu30OqCW2D0XpaZe1dUvJBl/CKE1JxPCwRTJfCF95MZQE5VESzJdQlAR/5485OE5u17Oe9cCaa62H5/O5rnmtMe57jDF/82auyfNdY4x7VncHAACA77jPehcAAACw0QhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlABgGVV1SVX971voe1FV/ela1wTA4u203gUAwPaqu397vWsAYDGcUQIAABgISgCsmao6tqq+Nve4raoumfr2qKrXVdXNVfWZqnpJVd1n6rvPtP6Zqrpp2m6Pqe+Aquqqem5V3VBVX66q51fV46vq41X1lar646GOX6yqT0zb/k1V7T/X95Sq+oeq+uq0Xy3zek6rqjcMdZxYVZ+tqi9W1YtXfxQBWAuCEgBrprv/vLt36+7dknxvkk8nOXfq/qMkeyR5ZJIfS3JCkudOfb8wPX586t8tyV3CT5L/NclBSY5N8gdJXpzkyUkOSfK/VdWPJUlVHZPkRUmekWRTkr+9s4aq2jPJm5O8JMmeSf4xyRO28WU+McmjkzwpyW9W1fdt4/4AbACCEgBrbjpT9GdJLunu11TVfTMLOKd29y3dfX2S/yfJz0+7PDvJ73f3p7v7a0lOTXJcVc3fa/tfuvub3X1Rkq8nObe7b+ruz2UWhn5w2u6XkvxOd3+iu29P8ttJHjedVfqpJFd3919297cyC1z/tI0v72Xd/Y3u/liSjyX5gW3cH4ANQFACYD2cnuRBSV44re+Z5P5JPjO3zWeS7D0tf+8SfTsl2Wuu7Qtzy99YYn23aXn/JH84XZL3lSRfyuzyur2n57nhzp26u+fXV2g+WN0697wAbEcEJQDWVFUdl+T4JM+cztokyReTfCuzEHOn/ZJ8blr+/BJ9t+euYWilbkjyS939PXOPXbr7fUluTLLvXK01vw7AjkNQAmDNVNUPZnYv0jHdffOd7d19R5LzkpxeVQ+aLoP7tSRvmDY5N8mvVtWBVbVbZpfL/fl06dy2+u9JTq2qQ6aa9qiqZ019FyQ5pKqeMV3W98IkD78bzwHAdk5QAmAtHZ3kwUneOzfz3YVT3y9ndm/Rp5O8N7N7mM6a+s5K8voklya5Lsk3p+23WXf/VZLfTfKmqvqXJFcm+cmp74tJnpXkjCT/nNnkEH93d54HgO1bzS6/BgAA4E7OKAEAAAwWFpSqat+qevf0hX5XVdV/nNofUlXvqqpPTT8fPLfPqVV1bVVdU1VPnWs/rKqumPpeOd1cCwAAsBCLPKN0e5L/1N3fl+TIJCdX1cFJTklycXcflOTiaT1T33GZfTHg05K8avpejSR5dZKTMrtW/KCpHwAAYCEWFpS6+8bu/vC0fEuST2T2HRVHJzln2uycJMdMy0cneVN339bd1yW5NskRVfWIJLt39/un77N43dw+AAAAq25N7lGqqgMy+0b0DybZq7tvTGZhKsnDps32zl2/1G/z1Lb3tDy2AwAALMROi36C6fsu3pzkV7r7X5a5vWipjl6mfannOimzS/Sy6667HvaYxzxm2wsGAAB2CB/60Ie+2N2blupbaFCqqvtlFpLe2N1vmZq/UFWP6O4bp8vqbpraN+eu336+T2bfxL55Wh7bv0t3n5nkzCQ5/PDD+/LLL1+11wIAANy7VNVnttS3yFnvKslrk3yiu39/ruv8JCdOyycmedtc+3FVtXNVHZjZpA2XTZfn3VJVR07HPGFuHwAAgFW3yDNKT0jy80muqKqPTm0vyuzbzs+rqucl+Wxm34Ce7r6qqs5LcnVmM+ad3N13TPu9IMnZSXZJcuH0AAAAWIiaTSR37+PSOwAAYDlV9aHuPnypvjWZ9Q4AAGB7IigBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAg4UFpao6q6puqqor59oeV1UfqKqPVtXlVXXEXN+pVXVtVV1TVU+daz+sqq6Y+l5ZVbWomgEAAJLFnlE6O8nThrbfS/Ky7n5ckt+c1lNVByc5Lskh0z6vqqr7Tvu8OslJSQ6aHuMxAQAAVtVOizpwd19aVQeMzUl2n5b3SPL5afnoJG/q7tuSXFdV1yY5oqquT7J7d78/SarqdUmOSXLhouoGYMd0wCkXrHcJa+L6M55+t/YzPsCOZmFBaQt+JcnfVNUrMjub9SNT+95JPjC33eap7VvT8ti+pKo6KbOzT9lvv/1Wr2oAAGCHstaTObwgya92975JfjXJa6f2pe476mXal9TdZ3b34d19+KZNm+5xsQAAwI5prYPSiUneMi3/RZI7J3PYnGTfue32yeyyvM3T8tgOAACwMGsdlD6f5Mem5Z9I8qlp+fwkx1XVzlV1YGaTNlzW3TcmuaWqjpxmuzshydvWuGYAAGAHs7B7lKrq3CRHJdmzqjYneWmS/yPJH1bVTkm+mel+ou6+qqrOS3J1ktuTnNzdd0yHekFmM+jtktkkDiZyAAAAFmqRs94dv4Wuw7aw/elJTl+i/fIkh65iaQAAAMta60vvAAAANjxBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADHZa7wIAAGBHd8ApF6x3CWvi+jOevt4lrJgzSgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADBYWlKrqrKq6qaquHNp/uaquqaqrqur35tpPraprp76nzrUfVlVXTH2vrKpaVM0AAADJYs8onZ3kafMNVfXjSY5O8tjuPiTJK6b2g5Mcl+SQaZ9XVdV9p91eneSkJAdNj7scEwAAYLUtLCh196VJvjQ0vyDJGd1927TNTVP70Une1N23dfd1Sa5NckRVPSLJ7t39/u7uJK9LcsyiagYAAEjW/h6lRyX5t1X1wap6T1U9fmrfO8kNc9ttntr2npbHdgAAgIXZaR2e78FJjkzy+CTnVdUjkyx131Ev076kqjops8v0st9++93jYgEAgB3TWp9R2pzkLT1zWZJvJ9lzat93brt9knx+at9nifYldfeZ3X14dx++adOmVS8eAADYMax1UHprkp9Ikqp6VJL7J/likvOTHFdVO1fVgZlN2nBZd9+Y5JaqOnKa7e6EJG9b45oBAIAdzMIuvauqc5MclWTPqtqc5KVJzkpy1jRl+L8mOXGapOGqqjovydVJbk9ycnffMR3qBZnNoLdLkgunBwAAwMIsLCh19/Fb6HrOFrY/PcnpS7RfnuTQVSwNAABgWWt96R0AAMCGJygBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwGCn9S4AkuSAUy5Y7xLWxPVnPH29SwAAYAWcUQIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABhsNShV1a5VdZ9p+VFV9TNVdb/FlwYAALA+VnJG6dIkD6iqvZNcnOS5Sc5eZFEAAADraSVBqbr71iTPSPJH3f2zSQ5ebFkAAADrZ0VBqap+OMmzk1wwte20uJIAAADW10qC0q8kOTXJX3X3VVX1yCTvXmxZAAAA62erZ4a6+z1J3lNVu07rn07ywkUXBgAAsF62GpSmy+5em2S3JPtV1Q8k+aXu/g+LLg6A1XHAKRdsfaN7gevPePp6lwDAvcRKLr37gyRPTfLPSdLdH0vyo4ssCgAAYD2t6Atnu/uGoemOBdQCAACwIaxk9robqupHknRV3T+z+5M+sdiyAAAA1s9Kzig9P8nJSfZOsjnJ46Z1AACAe6VlzyhV1X2T/EF3P3uN6gEAAFh3y55R6u47kmyaLrkDAADYIazkHqXrk/xdVZ2f5Ot3Nnb37y+qKAAAgPW0kqD0+elxnyQPWmw5AAAA62+rQam7X5YkVfWg2Wp/beFVAQAArKOtznpXVYdW1UeSXJnkqqr6UFUdsvjSAAAA1sdKpgc/M8mvdff+3b1/kv+U5E8WWxYAAMD6WUlQ2rW7333nSndfkmTXhVUEAACwzlYymcOnq+o3krx+Wn9OkusWVxIAAMD6WskZpV9MsinJW6bHnkmeu8iiAAAA1tNKZr37cpIXrkEtAAAAG8JKZr17V1V9z9z6g6vqbxZbFgAAwPpZyaV3e3b3V+5cmc4wPWxxJQEAAKyvlQSlb1fVfneuVNX+SXprO1XVWVV1U1VduUTfr1dVV9Wec22nVtW1VXVNVT11rv2wqrpi6ntlVdUKagYAALjbVhKUXpzkvVX1+qp6fZJLk5y6gv3OTvK0sbGq9k3ylCSfnWs7OMlxSQ6Z9nlVVd136n51kpOSHDQ9vuuYAAAAq2mrQam735nkh5L8eZLzkhzW3Vu9R6m7L03ypSW6/muS/zN3PSt1dJI3dfdt3X1dkmuTHFFVj0iye3e/v7s7yeuSHLO15wYAALgnVjKZwxOSfKO7355kjyQvmi6/22ZV9TNJPtfdHxu69k5yw9z65qlt72l5bN/S8U+qqsur6vKbb7757pQIAACwokvvXp3k1qr6gST/OclnMjuzs02q6oGZXcb3m0t1L9HWy7QvqbvP7O7Du/vwTZs2bWuJAAAASVYWlG6fLns7Oskru/sPkzzobjzXv0lyYJKPVdX1SfZJ8uGqenhmZ4r2ndt2nySfn9r3WaIdAABgYVYSlG6pqlOTPCfJBdMkC/fb1ifq7iu6+2HdfUB3H5BZCPqh7v6nJOcnOa6qdq6qAzObtOGy7r5xev4jp9nuTkjytm19bgAAgG2xkqB0bJLbkjxvCjV7J3n51naqqnOTvD/Jo6tqc1U9b0vbdvdVmU0UcXWSdyY5ubvvmLpfkORPM5vg4R+TXLiCmgEAAO62nba2wRSOfn9u/bNZwT1K3X38VvoPGNZPT3L6EttdnuTQrT0fAADAalnJGSUAAIAdiqAEAAAw2GJQqqrdl+nbbzHlAAAArL/lzihdcudCVV089L11IdUAAABsAMsFpfkve33IMn0AAAD3KssFpd7C8lLrAAAA9xrLTQ/+sKr6tczOHt25nGl908IrAwAAWCfLBaU/SfKgJZaT2RfAAgAA3CttMSh198u21FdVj19MOQAAAOtvuTNKd1FVByc5LsnxSb6a5PBFFQUAALCelg1KVbV/ZsHo+CS3J9k/yeHdff3iSwMAAFgfy33h7PuSvCPJ/ZI8s7sPS3KLkAQAANzbLTc9+M2ZTeCwV74zy51pwQEAgHu9LQal7j46yfcn+XCSl1XVdUkeXFVHrFVxAAAA62HZe5S6+6tJzkpyVlXtleTYJH9QVft2975rUSAAAMBaW+7Su7vo7i909yu7+0eSPHGBNQEAAKyrLZ5Rqqrzt7Lvz6xyLQAAABvCcpfe/XCSG5Kcm+SDSWpNKgIAAFhnywWlhyd5SmbfofTvk1yQ5NzuvmotCgMAAFgvy816d0d3v7O7T0xyZJJrk1xSVb+8ZtUBAACsg2VnvauqnZM8PbOzSgckeWWStyy+LAAAgPWz3GQO5yQ5NMmFSV7W3VeuWVUAAADraLkzSj+f5OtJHpXkhVX//1wOlaS7e/cF1wYAALAuthiUunvF37EEAABwbyIMAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAIOd1rsAAIDt3QGnXLDeJayJ6894+t3e1xixvXFGCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABgISgAAAANBCQAAYCAoAQAADAQlAACAgaAEAAAwEJQAAAAGghIAAMBAUAIAABjstKgDV9VZSf5dkpu6+9Cp7eVJfjrJvyb5xyTP7e6vTH2nJnlekjuSvLC7/2ZqPyzJ2Ul2SfKOJP+xu3tRdcNGdMApF6x3CWvi+jOefrf3NUYAwGpa5Bmls5M8bWh7V5JDu/uxST6Z5NQkqaqDkxyX5JBpn1dV1X2nfV6d5KQkB02P8ZgAAACramFBqbsvTfKloe2i7r59Wv1Akn2m5aOTvKm7b+vu65Jcm+SIqnpEkt27+/3TWaTXJTlmUTUDAAAk63uP0i8muXBa3jvJDXN9m6e2vaflsR0AAGBh1iUoVdWLk9ye5I13Ni2xWS/TvqXjnlRVl1fV5TfffPM9LxQAANghrXlQqqoTM5vk4dlzkzJsTrLv3Gb7JPn81L7PEu1L6u4zu/vw7j5806ZNq1s4AACww1jToFRVT0vyfyX5me6+da7r/CTHVdXOVXVgZpM2XNbdNya5paqOrKpKckKSt61lzQAAwI5nkdODn5vkqCR7VtXmJC/NbJa7nZO8a5Z78oHufn53X1VV5yW5OrNL8k7u7jumQ70g35ke/MJ8574mAACAhVhYUOru45dofu0y25+e5PQl2i9PcugqlgYAALCs9Zz1DgAAYEMSlAAAAAaCEgAAwEBQAgAAGAhKAAAAA0EJAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAY7rXcBO4IDTrlgvUtYE9ef8fT1LgEAAFaFM0oAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMFhYUKqqs6rqpqq6cq7tIVX1rqr61PTzwXN9p1bVtVV1TVU9da79sKq6Yup7ZVXVomoGAABIFntG6ewkTxvaTklycXcflOTiaT1VdXCS45IcMu3zqqq677TPq5OclOSg6TEeEwAAYFUtLCh196VJvjQ0H53knGn5nCTHzLW/qbtv6+7rklyb5IiqekSS3bv7/d3dSV43tw8AAMBCrPU9Snt1941JMv182NS+d5Ib5rbbPLXtPS2P7UuqqpOq6vKquvzmm29e1cIBAIAdx0aZzGGp+456mfYldfeZ3X14dx++adOmVSsOAADYsax1UPrCdDldpp83Te2bk+w7t90+ST4/te+zRDsAAMDCrHVQOj/JidPyiUneNtd+XFXtXFUHZjZpw2XT5Xm3VNWR02x3J8ztAwAAsBA7LerAVXVukqOS7FlVm5O8NMkZSc6rqucl+WySZyVJd19VVecluTrJ7UlO7u47pkO9ILMZ9HZJcuH0AAAAWJiFBaXuPn4LXU/awvanJzl9ifbLkxy6iqUBAAAsa6NM5gAAALBhCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABoISAADAQFACAAAYCEoAAAADQQkAAGAgKAEAAAwEJQAAgIGgBAAAMBCUAAAABusSlKrqV6vqqqq6sqrOraoHVNVDqupdVfWp6eeD57Y/taquraprquqp61EzAACw41jzoFRVeyd5YZLDu/vQJPdNclySU5Jc3N0HJbl4Wk9VHTz1H5LkaUleVVX3Xeu6AQCAHcd6XXq3U5JdqmqnJA9M8vkkRyc5Z+o/J8kx0/LRSd7U3bd193VJrk1yxBrXCwAA7EDWPCh19+eSvCLJZ5PcmOSr3X1Rkr26+8ZpmxuTPGzaZe8kN8wdYvPUBgAAsBDV3Wv7hLN7j96c5NgkX0nyF0n+Mskfd/f3zG335e5+cFX9tyTv7+43TO2vTfKO7n7zEsc+KclJ0+qjk1yz0Bezse2Z5IvrXcQGZ4yWZ3y2zhgtz/hsnTFanvFZnvHZOmO0POOT7N/dm5bq2GmtK0ny5CTXdffNSVJVb0nyI0m+UFWP6O4bq+oRSW6att+cZN+5/ffJ7FK979LdZyY5c2GVb0eq6vLuPny969jIjNHyjM/WGaPlGZ+tM0bLMz7LMz5bZ4yWZ3yWtx73KH02yZFV9cCqqiRPSvKJJOcnOXHa5sQkb5uWz09yXFXtXFUHJjkoyWVrXDMAALADWfMzSt39war6yyQfTnJ7ko9kdhZotyTnVdXzMgtTz5q2v6qqzkty9bT9yd19x1rXDQAA7DjW49K7dPdLk7x0aL4ts7NLS21/epLTF13XvYxLELfOGC3P+GydMVqe8dk6Y7Q847M847N1xmh5xmcZaz6ZAwAAwEa3Xt+jBAAAsGEJSgAAAANBaTtWVddX1Z73dJvVfs6NYq3Gp6p+oar+eFo+u6qeeU+Ot94WMW5V9ayq+kRVvfueV7h2FvkeqqpLqmqrU7Ju9N+5ezpGVXVAVV25mOo2jgW/lzb0e2SlVmOMquprq1/ZxrGgz+d3VNX3LNF+WlX9+t2pcyPwftqy1X4fzb9Xpn8Tfe9q1LkRCErAwtTMfZI8L8l/6O4fX++aAPjO53N3/1R3f2W969leVNV917uGDe4XkghK3D3TX0//oar+tKqurKo3VtWTq+rvqupTVXVEVT2kqt5aVR+vqg9U1WOnfR9aVRdV1Ueq6jVJau64z6mqy6rqo1X1mpX8IlfV46fneEBV7VpVV1XVoVV1n6p61bT+9umvTfNnSf7z9FyXVdX/cm8dn2m/t1bVh6axOGmu/blV9cmqek+SJwy7Pbmq/nbq/3erMCwrqXPDjNtUyyeq6lWZfQ3AbyR5YpL/XlUvX9AQjM+/IcZi2u83pnreVVXn1l3/QvucqnrfVOcRW6thtWy0MZrb/5HTcR9fs79KvqWq3jnV9Htz232tqk6vqo9Nte21aoNz13o21Dhtbb+5370/qdln1kVVtcuqDsp317Shxmhu/92q6uKq+nBVXVFVR0/tu1bVBdN758qqOnZVB2TpWjbMGNV3fz7vW3NnDqrqxVV1TVX9v0kevZgR2Wp9G2KshrqOqqp3V9WfJblidV/1imvYUGOz1HulZv9WPDzJG6fjLfTzZ010t8caPpIckNn3QX1/ZkH1Q0nOyuxNe3SStyb5oyQvnbb/iSQfnZZfmeQ3p+WnJ+kkeyb5viR/neR+U9+rkpwwLV+fZM9l6vm/k7wiyX9LcurU9swk75jqe3iSLyd55tzxXjwtn5Dk7ffy8XnI9HOXJFcmeWiSR2T2XV+bktw/yd8l+eNpu7OTvHOq/aAkm5M8YEd6X021fDvJkXNtlyQ5fEf7Hcvsfxgfnd4/D0ryqSS/PjcmfzIt/2iSK5er4V48Rgdk9rv16My+V+9xU/svJPl0kj2SPCDJZ5LsO/V1kp+eln8vyUt2gPfSVvebq/fOMTwvyXN2lN+3qf9r08+dkuw+Le+Z5Nqppp/L9Hs39e2xyPHZaGOUpT+f73z/HJZZCHhgkt2nMfv1RY/PRh2r4f10VJKvJzlwLcdjo47Ncjl59D4AAAbnSURBVO+VrOH/79fisS7fo0Su6+4rkqSqrkpycXd3VV2R2S/C/pl9mKe7/+f0l4A9MvvH1DOm9guq6svT8Z6U2Zv276sqmf2j7KYV1vJbSf4+yTeTvHBqe2KSv+jubyf5p/ru+0rOnfv5X1f8qlduI43PC6vqZ6flfTMLPw9Pckl33zzV+OdJHjW3z3nT2H2qqj6d5DGZ/WN50TbSuH2muz+wOi/rbtkoY/HEJG/r7m9Mtfz10H/u9FyXVtXuNbtPYEs1rLaNMkbJ7I8Ob0vyc9191Vz7xd391anGq6eabkjyr0nePm3zoSRP2cbXvi02yjitdL/ruvvOz5sPTTUu2kYZo3mV5Ler6kczCwZ7J9krs3/cvaKqfjezP/T97d18zdtqI43Rlj6f/22Sv+ruW6c6z9/2l7kqNtJYzbusu6+7+y9rVWyUsdko75WFE5TWx21zy9+eW/92Zv9Nbl9inx5+zqsk53T3qXejlock2S3J/TL7q+3Xs/VLfXoLy6tlQ4xPVR2V5MlJfri7b62qSzIboy09z1jLltYXZUOM2+Trd2Of1bRRxmJbfpe2VsNq2yhjlCRfzSwAPSHJfFCar/GOfOf/Wd/q7l6ifRE2yjitdL9xzNbi0peNMkbznp1ZAD+su79VVddndnb/k1V1WJKfSvI7VXVRd//WPXieldpIY7Tc5/Na/f9qORtprOat9//Xko01NhvhvbJw7lHamC7N7EP+zn+sf7G7/2Vo/8kkD562vzjJM6vqYVPfQ6pq/xU+15mZ3UPyxiS/O7W9N8nP1exepb0yO+U879i5n+/fple2OtZqfPZI8uUpJD0myZFT+weTHDX9peZ+SZ417Pesaez+TZJHJrnmbr7O1baW76uNbq3G4r1Jfrpm9wHultklD/OOnY73xCRfnc6ebKmGtbaW75d/TXJMkhOq6t+v2itYG2s1Ttvz7+N6fPbskeSmKST9eGZ/aU/NZuO6tbvfkNll5z90T17YKtoIn8+XJvnZqtqlqh6U5Kfv4fEWZSOM1Ua1VmOz3HvllswuNb9XcEZpYzotyf+oqo8nuTXJiVP7y5KcW1UfTvKezO6TSXdfXVUvSXJRzWYY+1aSkzO7pn+LquqEJLd395/V7Oa991XVTyR5c2anY69M8snMgsFX53bduao+mFnQPn4VXu+2Oi1rMD6Z3Wv0/Ol5rknygel4N1bVaZmFxBszuyF2/ubHa6bn3yvJ87v7m/fo1a6e07I247Y9OC1rMBbd/ffTJQkfm7a9PHf9XfpyVb0vs2u8f3G5GtbBaVnD90t3f71mk5+8q6o2wl9uV+q0rM17aXv+fTwta//Z88Ykf11Vl2d26fM/TO3fn+TlVfXt6bgvuCcvbBWdlnX+fO7uD9fsUvKPTsdZq8sSt9Vp8f+yLTkta/N5tNx75ezMJm/6RmZX5HxjlV7buqjvXL0A31FVu3X316rqoUkuS/KE7v6n9a4Ltjdzv0sPzOyvcCd194fXuy4AYHnOKLElb6/ZjeX3T/JfhCS4286sqoMzu7/tHCEJALYPzijtAKazQhcv0fWk7v7nta5nozE+d49x+w5jsXXGaGWM09YZo60zRitnrLbM2AhKAAAA38WsdwAAAANBCQAAYCAoAbBdqKquqtfPre9UVTdX1du38TjXV9We93QbAO7dBCUAthdfT3JoVe0yrT8lyefWsR4A7sUEJQC2Jxcmefq0fHySc+/smL5V/q1V9fGq+kBVPXZqf2hVXVRVH6mq1ySpuX2eU1WXVdVHq+o105dvZ65/16q6oKo+VlVXVtWxi3+JAGwEghIA25M3JTmuqh6Q5LFJPjjX97IkH+nuxyZ5UZLXTe0vTfLe7v7BJOcn2S9Jqur7khyb2RdqPy7JHUmePTzf05J8vrt/oLsPTfLOxbwsADYaXzgLwHajuz9eVQdkdjbpHUP3E5P83LTd/5zOJO2R5EeTPGNqv6Cqvjxt/6QkhyX5+6pKkl2S3DQc84okr6iq303y9u7+21V/UQBsSIISANub85O8IslRSR46115LbNvDz3mV5JzuPnVLT9Tdn6yqw5L8VJLfqaqLuvu37lbVAGxXXHoHwPbmrCS/1d1XDO2XZrp0rqqOSvLF7v6Xof0nkzx42v7iJM+sqodNfQ+pqv3nD1hV35vk1u5+Q2bh7IcW8ooA2HCcUQJgu9Ldm5P84RJdpyX5H1X18SS3Jjlxan9ZknOr6sNJ3pPks9Nxrq6qlyS5qKruk+RbSU5O8pm5Y35/kpdX1ben/hes/isCYCOq7qWuRgAAANhxufQOAABgICgBAAAMBCUAAICBoAQAADAQlAAAAAaCEgAAwEBQAgAAGAhKAAAAg/8Pvr85Noqn3goAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAE_vales = model_dict.values()\n",
    "models = ['model_xgb','model_adb','model_rf','model_gbd','model_knn','model_eln','model_las','model_rid','model_lr','model_dt']\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.ylim(800,2000)\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAE scores')\n",
    "plt.bar(models,MAE_vales)\n",
    "plt.title('zoomed in')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1158.820772507829, 1525.3463970284195, 1211.651647792013, 1210.795618910887, 1459.4503827092028, 1804.9400204491346, 1804.9400204491346, 1277.3354617593623, 1277.3570621381039, 1754.3839458074149])\n"
     ]
    }
   ],
   "source": [
    "print(MAE_vales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* Trained different kinds of regression models without any hyperparameter tuning.\n",
    "* over all diff kinds of models some models did worse than other as our data has 130 dimenstions and not all models can do well with high dimension data.\n",
    "* Even without any hyper parameter tuning , XGBOOST gave the best MAE value on the cv data.\n",
    "* This cross validate is only for our purpose to check the model accuracy as test data that we were given doesnt have target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data after OHE : (188318, 1155)\n"
     ]
    }
   ],
   "source": [
    "data_ohe = pd.get_dummies(data=train_data, columns=categorical_features)\n",
    "data_ohe.reset_index(drop = True, inplace = True)\n",
    "print('Shape of data after OHE :',data_ohe.shape)\n",
    "\n",
    "x_train = data_ohe.drop(['id','loss'],axis =1)\n",
    "y_train = np.log(data_ohe['loss'])\n",
    "\n",
    "x_train_ohe,x_cv_ohe,y_train_ohe,y_cv_ohe = train_test_split(x_train,y_train,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying XGBRegressor on OHE features.\n",
    "* Main goal here is to check which encoding works better for these kinds of features.\n",
    "* we will decide based on cv MAE score on when both encodings on XGBRegressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1165.9142026607606\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()\n",
    "model.fit(x_train_ohe,y_train_ohe)\n",
    "pred =  model.predict(x_cv_ohe)\n",
    "a = mean_absolute_error(np.exp(y_cv_ohe), np.exp(pred))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "* we can see that MAE value of XGBOOSTREGRESSOR with out hyer parameter tning.\n",
    "* Label encoder data  - 1158.8207\n",
    "* OHE data - 1165.91420\n",
    "* we can say that label encoding works better than OHE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning for XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisrt hyper parameter tune results:{'max_depth': 10, 'min_child_weight': 1}\n",
      "Second hyper parameter tune results:{'gamma': 1, 'learning_rate': 0.1}\n",
      "Third hyper parameter tune results:{'colsample_bytree': 0.6, 'subsample': 0.8}\n",
      "***** Final Hyper Parameter Tuning *****\n",
      "Final hyper parameter tune results:{'colsample_bytree': 0.5,'subsample': 0.8,'learning_rate': 0.1,'max_depth': 12,'min_child_weight': 1,'gamma':1}\n"
     ]
    }
   ],
   "source": [
    "#  reference\n",
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "# https://blog.cambridgespark.com/hyperparameter-tuning-in-xgboost-4ff9100a3b2f\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,15,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "clf = XGBRegressor(learning_rate =0.01, n_estimators=140, max_depth=5,\n",
    "                min_child_weight=1, gamma=0.005, subsample=0.9, colsample_bytree=0.75,\n",
    "                objective= 'reg:linear', scale_pos_weight=1, seed=0, \n",
    "                param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator =clf,param_grid = param_test1)\n",
    "gsearch1.fit(x_train,y_train)\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':[11,12,13),\n",
    " 'min_child_weight':range(1,3)\n",
    "}\n",
    "clf = XGBRegressor(learning_rate =0.01, n_estimators=140, max_depth=5,\n",
    "                min_child_weight=1, gamma=0.005, subsample=0.9, colsample_bytree=0.75,\n",
    "                objective= 'reg:linear', scale_pos_weight=1, seed=0, \n",
    "                param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator =clf,param_grid = param_test1)\n",
    "gsearch1.fit(x_train,y_train)\n",
    "print('Fisrt hyper parameter tune results:',gsearch1.best_params_)\n",
    "\n",
    "\n",
    "param_test1 = {\n",
    " 'learning_rate':[0.01,0.1,0,1],\n",
    " 'gamma':[0.02,0.1,1,1.02]\n",
    "}\n",
    "\n",
    "clf = XGBRegressor(learning_rate =0.01, n_estimators=140, max_depth=5,\n",
    "                min_child_weight=1, gamma=0.005, subsample=0.9, colsample_bytree=0.75,\n",
    "                objective= 'reg:linear', scale_pos_weight=1, seed=0, \n",
    "                param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch2 = GridSearchCV(estimator =clf,param_grid = param_test1)\n",
    "gsearch2.fit(x_train,y_train)\n",
    "print('Second hyper parameter tune results:',gsearch2.best_params_)\n",
    "\n",
    "\n",
    "param_test1 = {\n",
    " 'colsample_bytree': [0.5,0.6,0.7,0.75],\n",
    " 'subsample' :[0.9,0.8,0.7]\n",
    "}\n",
    "\n",
    "clf = XGBRegressor(learning_rate =0.01, n_estimators=140, max_depth=5,\n",
    "                min_child_weight=1, gamma=0.005, subsample=0.9, colsample_bytree=0.75,\n",
    "                objective= 'reg:linear', scale_pos_weight=1, seed=0, \n",
    "                param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "gsearch3 = GridSearchCV(estimator =clf,param_grid = param_test1)\n",
    "gsearch3.fit(x_train,y_train)\n",
    "print('Third hyper parameter tune results:',gsearch3.best_params_)\n",
    "\n",
    "print('***** Final Hyper Parameter Tuning *****')\n",
    "\n",
    "param_test1 = {\n",
    "    'colsample_bytree': [0.4,0.5,0.6],\n",
    "    'subsample': [0.8,0.9,0.7],\n",
    "    'gamma': [0.015,0.01,0.1],\n",
    "    'learning_rate': [0.1,0.01,0.15],\n",
    "    'max_depth': [10,11,12], \n",
    "    'min_child_weight': [1,2,3]\n",
    "}\n",
    "\n",
    "clf = XGBRegressor(n_estimators=140,objective= 'reg:linear', scale_pos_weight=1, seed=0,silent =1,\n",
    "                 param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5,num_parallel_tree = 1)\n",
    "\n",
    "gsearch4 = GridSearchCV(estimator =clf,param_grid = param_test1)\n",
    "gsearch4.fit(x_train,y_train)\n",
    "print('Final hyper parameter tune results:',gsearch4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We tuned 2 parameters and got {'max_depth': 10, 'min_child_weight': 1}\n",
    "* We tuned 2 parameters and got {'gamma': 1, 'learning_rate': 0.1}\n",
    "* We tuned 2 parameters and got {'colsample_bytree': 0.6, 'subsample': 0.8}\n",
    "* Final hyper parameter tune results:{'colsample_bytree': 0.5,'subsample': 0.8,'learning_rate': 0.1,'max_depth': 12,'min_child_weight': 1,'gamma':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:7.26350+0.00124\ttest-rmse:7.26350+0.00503\ttrain-mae:3235.56396+4.96432\ttest-mae:3235.56401+19.85736\n",
      "[500]\ttrain-rmse:0.46110+0.00029\ttest-rmse:0.48638+0.00170\ttrain-mae:1118.87234+1.77473\ttest-mae:1179.87725+9.47952\n",
      "[1000]\ttrain-rmse:0.43163+0.00035\ttest-rmse:0.47696+0.00134\ttrain-mae:1026.26772+1.53510\ttest-mae:1141.59067+7.82845\n",
      "[1500]\ttrain-rmse:0.41921+0.00039\ttest-rmse:0.47563+0.00126\ttrain-mae:993.74723+1.49601\ttest-mae:1137.34856+7.88345\n",
      "[2000]\ttrain-rmse:0.41051+0.00038\ttest-rmse:0.47523+0.00120\ttrain-mae:971.77592+1.49968\ttest-mae:1136.02644+7.71141\n"
     ]
    }
   ],
   "source": [
    "# Finding best rounds via cross validate xgboost with 50 early stoppings.\n",
    "res = xgb.cv(params, xgtrain, num_boost_round=2500, nfold=5, stratified=False,\n",
    "         early_stopping_rounds=50, verbose_eval=500, show_stdv=True, feval=log_xgboost_eval_mae, maximize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble-CV: 0.40487799999999996+0.0002799499955349193\n",
      "Best n rounds are : 2418\n"
     ]
    }
   ],
   "source": [
    "best_nrounds = res.shape[0] - 1\n",
    "cv_mean = res.iloc[-1, 0]\n",
    "cv_std = res.iloc[-1, 1]\n",
    "print('Ensemble-CV: {0}+{1}'.format(cv_mean, cv_std))\n",
    "print('Best n rounds are :',best_nrounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2016\n",
    "params = {\n",
    "        'min_child_weight': 1,\n",
    "        'eta': 0.01,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 12,\n",
    "        'subsample': 0.8,\n",
    "        'alpha': 1,\n",
    "        'gamma': 1,\n",
    "        'silent': 1,\n",
    "        'verbose_eval': True,\n",
    "        'seed': RANDOM_STATE\n",
    "    }\n",
    "\n",
    "xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "xgtest = xgb.DMatrix(x_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, best_nrounds, feval=log_xgboost_eval_mae)\n",
    "\n",
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "\n",
    "sub = pd.read_csv('../input/submission/sample_submission.csv')\n",
    "sub['loss'] = prediction\n",
    "sub.to_csv('submissions1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* we modelled xgb.train with best rounds we got in cross validate xgboost.\n",
    "* once we predicted and converted to csv file we got a score of 1114.48304 , which is very close to leaderboard score at kaggle which is 1109.70772.\n",
    "* So far this is the best model that we built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance.\n",
    "* importance_type\n",
    "* ‘weight’ - the number of times a feature is used to split the data across all trees.\n",
    "* ‘gain’ - the average gain across all splits the feature is used in.\n",
    "* ‘cover’ - the average coverage across all splits the feature is used in.\n",
    "* ‘total_gain’ - the total gain across all splits the feature is used in.\n",
    "* ‘total_cover’ - the total coverage across all splits the feature is used in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat80', 162.2719000009297), ('cat12', 87.26782582080102), ('cat79', 79.60965513514314), ('cat57', 36.22010919383452), ('cat87', 30.03140810011797), ('cat81', 29.693861800894787), ('cat10', 24.879644147797677), ('cat53', 21.933176503048287), ('cat1', 19.673499734367155), ('cat44', 17.1280969359697), ('cat38', 16.446144060439853), ('cat11', 12.372713314280027), ('cat111', 11.300631667603176), ('cat13', 11.150816345742737), ('cat72', 11.056952663214664), ('cat89', 10.472847536806889), ('cat5', 9.66238212825089), ('cat2', 9.385492227500148), ('cat26', 9.033314502639739), ('cat9', 8.8588270898421), ('cat7', 8.745802133176394), ('cat25', 7.884212813852916), ('cat52', 7.610929603415244), ('cat49', 7.506278523914056), ('cat3', 6.8633412871073425), ('cat4', 6.460700377858011), ('cat37', 6.074376528546785), ('cat36', 5.475283390459903), ('cont2', 5.330136365055739), ('cat100', 5.128326088400257), ('cat6', 4.782938554946328), ('cat76', 4.761914553074233), ('cat50', 4.716160970387901), ('cat16', 4.668694864690523), ('cat31', 4.545985257465816), ('cat42', 4.194686254431111), ('cat73', 3.9990127404664686), ('cat27', 3.8757947547883065), ('cat94', 3.8281573060369283), ('cat77', 3.699425639175312), ('cat23', 3.5583700867297834), ('cat82', 2.9704369436202427), ('cont7', 2.6083438638298038), ('cat39', 2.594989753456896), ('cat32', 2.4964056302866884), ('cont14', 2.4862672220743054), ('cat8', 2.4584368957266305), ('cat75', 2.4578839577577796), ('cat88', 2.456847187166193), ('cat51', 2.4037665945765965), ('cat40', 2.3601147411231134), ('cat54', 2.1724492691789963), ('cont12', 2.1548726124065687), ('cat67', 2.138611455339621), ('cat78', 2.1275552859603355), ('cat56', 2.119092250287673), ('cat108', 2.107077452252686), ('cat71', 2.083377663484285), ('cat45', 2.0324623228757703), ('cat28', 2.0240190406499377), ('cat19', 1.9708223011388661), ('cat91', 1.8350194745999693), ('cat21', 1.8114949283019706), ('cat55', 1.7992260803458642), ('cat65', 1.7887936179105968), ('cont3', 1.7572254676754022), ('cat29', 1.7059455420620335), ('cat95', 1.704282398467205), ('cont11', 1.6903582992642767), ('cat43', 1.6562692287876462), ('cat98', 1.5992763398149132), ('cat63', 1.5878286060111113), ('cat61', 1.5735160639275005), ('cat35', 1.5389363873538464), ('cat66', 1.5364869414720206), ('cat86', 1.5248936999202132), ('cat84', 1.4741572863204697), ('cat48', 1.4724569371933958), ('cat22', 1.4594707172642853), ('cat41', 1.4570023779950732), ('cont9', 1.440752193488572), ('cat112', 1.3921757372012074), ('cat83', 1.3749906997912258), ('cat93', 1.372136627022589), ('cat59', 1.3661525163945527), ('cat17', 1.3461574711682818), ('cont1', 1.341368053357382), ('cont13', 1.3248172837463514), ('cont4', 1.3191107836741418), ('cat104', 1.3168907955584739), ('cont10', 1.3021787319268587), ('cont6', 1.296879087874962), ('cont8', 1.2959460725368623), ('cat68', 1.287792196479532), ('cat85', 1.2816822661033422), ('cat74', 1.2782863484293858), ('cat107', 1.2749540567850863), ('cat115', 1.2623486125123637), ('cat30', 1.2477331129576388), ('cat97', 1.2451623504281804), ('cont5', 1.227409877388042), ('cat14', 1.2223128290318848), ('cat18', 1.2174422131989053), ('cat33', 1.2104047777509446), ('cat58', 1.2010935745333335), ('cat24', 1.1862865853136468), ('cat60', 1.1781883534780875), ('cat46', 1.1716171955450299), ('cat69', 1.1208789612027026), ('cat34', 1.0979491698819668), ('cat47', 1.06792695978481), ('cat70', 0.9632211161666668), ('cat20', 0.9020500200852942), ('cat15', 0.8047078450999999), ('cat64', 0.6462872829999999), ('cat62', 0.5642320398666666)]\n"
     ]
    }
   ],
   "source": [
    "# reference - https://stackoverflow.com/questions/37627923/how-to-get-feature-importance-in-xgboost\n",
    "# reference - https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value\n",
    "\n",
    "feature_imp = model.get_score(importance_type='gain')\n",
    "sorted_feature_imp = sorted(feature_imp.items(), key=lambda x: x[1],reverse=True)    \n",
    "print(sorted_feature_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least important features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least important 0 feature is  cat24\n",
      "least important 1 feature is  cat60\n",
      "least important 2 feature is  cat46\n",
      "least important 3 feature is  cat69\n",
      "least important 4 feature is  cat34\n",
      "least important 5 feature is  cat47\n",
      "least important 6 feature is  cat70\n",
      "least important 7 feature is  cat20\n",
      "least important 8 feature is  cat15\n",
      "least important 9 feature is  cat64\n",
      "least important 10 feature is  cat62\n",
      "*********\n",
      "['cat24', 'cat60', 'cat46', 'cat69', 'cat34', 'cat47', 'cat70', 'cat20', 'cat15', 'cat64', 'cat62']\n"
     ]
    }
   ],
   "source": [
    "least_imp_features = []\n",
    "for i,x in enumerate(list(sorted_feature_imp)[-11:]):\n",
    "    print('least important',i,'feature is ',x[0])\n",
    "    least_imp_features.append(x[0])\n",
    "    \n",
    "print('*********')\n",
    "print(least_imp_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "*  we can see that 'cat24', 'cat60', 'cat46', 'cat69', 'cat34', 'cat47', 'cat70', 'cat20', 'cat15', 'cat64', 'cat62' -  these are least important features for the trined model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Basic Deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "188318/188318 [==============================] - 9s 46us/step - loss: 1.1130\n",
      "Epoch 2/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.7692\n",
      "Epoch 3/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.6917\n",
      "Epoch 4/25\n",
      "188318/188318 [==============================] - 8s 45us/step - loss: 0.6379\n",
      "Epoch 5/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.5907\n",
      "Epoch 6/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.5595\n",
      "Epoch 7/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.5392\n",
      "Epoch 8/25\n",
      "188318/188318 [==============================] - 8s 42us/step - loss: 0.5239\n",
      "Epoch 9/25\n",
      "188318/188318 [==============================] - 8s 42us/step - loss: 0.5115\n",
      "Epoch 10/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.5001\n",
      "Epoch 11/25\n",
      "188318/188318 [==============================] - 8s 45us/step - loss: 0.4895\n",
      "Epoch 12/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4810\n",
      "Epoch 13/25\n",
      "188318/188318 [==============================] - 9s 46us/step - loss: 0.4726\n",
      "Epoch 14/25\n",
      "188318/188318 [==============================] - 9s 46us/step - loss: 0.4654\n",
      "Epoch 15/25\n",
      "188318/188318 [==============================] - 8s 42us/step - loss: 0.4583\n",
      "Epoch 16/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4524\n",
      "Epoch 17/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4445\n",
      "Epoch 18/25\n",
      "188318/188318 [==============================] - 8s 44us/step - loss: 0.4397\n",
      "Epoch 19/25\n",
      "188318/188318 [==============================] - 9s 46us/step - loss: 0.4344\n",
      "Epoch 20/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4295\n",
      "Epoch 21/25\n",
      "188318/188318 [==============================] - 8s 42us/step - loss: 0.4247\n",
      "Epoch 22/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4217\n",
      "Epoch 23/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4182\n",
      "Epoch 24/25\n",
      "188318/188318 [==============================] - 8s 42us/step - loss: 0.4154\n",
      "Epoch 25/25\n",
      "188318/188318 [==============================] - 8s 43us/step - loss: 0.4118\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "def neural_network_model(x_train):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(400, input_dim = x_train.shape[1], init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.4))\n",
    "   \n",
    "    model.add(Dense(200, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(100, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(50, init = 'he_normal'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, init = 'he_normal'))\n",
    "    model.compile(loss = 'mae', optimizer = 'adam')\n",
    "    return(model)\n",
    "\n",
    "\n",
    "model=neural_network_model(x_train)\n",
    "n_epochs = 25\n",
    "fit = model.fit(x_train,y_train, nb_epoch = n_epochs,batch_size=250,verbose = 1)\n",
    "p_test = np.exp(model.predict(x_test)) - 200\n",
    "sub = pd.read_csv('../input/submission/sample_submission.csv')\n",
    "sub['loss'] = p_test\n",
    "sub.to_csv('submissions2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "* after submitting the csv file in kaggle we got a score of 1359.49641, which is really bad considering we got a score of around 1119 using normal xgboost.\n",
    "* there are multiple reasons i can think of why this neural network did bad.\n",
    "1. first and foremost we have to accept the fact that not every probelm needs neural networks as a solution\n",
    "1. we havent tuned our hyperparameters in neural networks, so we can increase our score after tuning our neural network,\n",
    "1. there are many possible cobinations of number of neurons in each layer, droup out rate, activations that we can use....and some other parmeters.\n",
    "1. we might increase our score after hyper parameter tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
